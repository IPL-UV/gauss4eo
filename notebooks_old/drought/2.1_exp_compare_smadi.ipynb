{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "cwd = os.getcwd()\n",
    "sys.path.insert(0, f'{cwd}/../../')\n",
    "sys.path.insert(0, '/home/emmanuel/code/py_esdc')\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# drought tools\n",
    "from src.data.drought.loader import DataLoader\n",
    "from src.features.drought.build_features import (\n",
    "    get_cali_geometry,\n",
    "    mask_datacube,\n",
    "    smooth_vod_signal,\n",
    "    remove_climatology,\n",
    "    get_cali_emdata,\n",
    "    get_drought_years,\n",
    "    get_density_cubes,\n",
    "    get_common_elements_many,\n",
    "    normalize\n",
    ")\n",
    "from src.visualization.drought.analysis import plot_mean_time\n",
    "\n",
    "# esdc tools\n",
    "from esdc.subset import select_pixel\n",
    "from esdc.shape import ShapeFileExtract, rasterize\n",
    "from esdc.transform import DensityCubes\n",
    "\n",
    "# RBIG\n",
    "from src.models.train_models import run_rbig_models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "plt.style.use(['fivethirtyeight', 'seaborn-poster'])\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "region = 'conus'\n",
    "sampling = '14D'\n",
    "\n",
    "drought_cube = DataLoader().load_data(region, sampling)\n",
    "\n",
    "# Subset california\n",
    "cali_geoms = get_cali_geometry()\n",
    "\n",
    "drought_cube = mask_datacube(drought_cube, cali_geoms)\n",
    "\n",
    "# interpolate\n",
    "# interpolation arguments\n",
    "interp_dim = 'time'\n",
    "method = 'linear'\n",
    "\n",
    "# do interpolation\n",
    "drought_cube = drought_cube.interpolate_na(\n",
    "    dim=interp_dim, \n",
    "    method=method\n",
    ")\n",
    "\n",
    "# remove climatology\n",
    "drought_cube, _ = remove_climatology(drought_cube)\n",
    "\n",
    "\n",
    "# drought years\n",
    "drought_years = {\n",
    "    \"2010\": False,\n",
    "    \"2011\": False,\n",
    "    \"2012\": True,\n",
    "    \"2013\": False,\n",
    "    \"2014\": True,\n",
    "    \"2015\": True,\n",
    "}\n",
    "\n",
    "# MI elements\n",
    "common_vars = [\n",
    "    ('VOD', 'NDVI'),\n",
    "    ('VOD', 'LST'),\n",
    "    ('VOD', 'SM'),\n",
    "    ('NDVI', 'LST'),\n",
    "    ('NDVI', 'SM'),\n",
    "    ('LST', 'SM')\n",
    "]\n",
    "\n",
    "variables = [\n",
    "    'VOD', 'NDVI', 'SM', 'LST'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment I - Individual Measurements\n",
    "\n",
    "In this part, we will look at the standard individual measurements such as \n",
    "\n",
    "* Entropy, H\n",
    "* Total Correlation, TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:03<?, ?it/s, Dims=1, Variable=LST] \n"
     ]
    }
   ],
   "source": [
    "time_steps = range(1,12)\n",
    "spatial = 1\n",
    "results_df_single = pd.DataFrame()\n",
    "\n",
    "\n",
    "with tqdm(drought_cube.groupby('time.year')) as years_bar:\n",
    "    # group datacube by years\n",
    "    for iyear, icube in years_bar:\n",
    "\n",
    "        # Loop through time steps\n",
    "        for itime_step in time_steps:\n",
    "\n",
    "            # extract density cubes\n",
    "            vod_df, lst_df, ndvi_df, sm_df = get_density_cubes(icube, spatial, itime_step)\n",
    "\n",
    "\n",
    "            # get common elements\n",
    "            dfs = get_common_elements_many([vod_df, lst_df, ndvi_df, sm_df])\n",
    "            vod_df, lst_df, ndvi_df, sm_df = dfs[0], dfs[1], dfs[2], dfs[3]\n",
    "\n",
    "\n",
    "            variables = {\n",
    "                'VOD': vod_df,\n",
    "                'NDVI': ndvi_df,\n",
    "                'SM': sm_df,\n",
    "                'LST': lst_df\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "            # do calculations for H, TC\n",
    "            for iname, idata in variables.items():\n",
    "                \n",
    "\n",
    "\n",
    "                # normalize data\n",
    "                X_norm = StandardScaler().fit_transform(idata)\n",
    "\n",
    "                # entropy, total correlation\n",
    "                tc, h, t_ = run_rbig_models(X_norm, measure=\"t\", random_state=123)\n",
    "\n",
    "                # get H and TC\n",
    "                results_df_single = results_df_single.append({\n",
    "                    'year': iyear,\n",
    "                    'drought': drought_years[iyear],\n",
    "                    'samples': X_norm.shape[0],\n",
    "                    'dimensions': X_norm.shape[1],\n",
    "                    'temporal': itime_step,\n",
    "                    'variable': iname,\n",
    "                    'tc': tc,\n",
    "                    'h': h,\n",
    "                    'time': t_,\n",
    "\n",
    "                }, ignore_index=True)\n",
    "            \n",
    "                postfix = dict(\n",
    "                    Dims=f\"{itime_step}\",\n",
    "                    Variable=f\"{iname}\",\n",
    "                )\n",
    "                years_bar.set_postfix(postfix)\n",
    "            # do calculations for \n",
    "            break\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment II - Comparing Measurements\n",
    "\n",
    "In this experiment, we will look at different combinations of variables. The following measurements will be calculated and compared:\n",
    "\n",
    "* Pearson Correlation\n",
    "* Spearman Correlation\n",
    "* Mutual Information\n",
    "* HSIC..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:18<?, ?it/s, Year=2010, Dims=1, Variables=LST-SM, MI=0.183, Pear=-0.232, Spear=-0.214]  \n"
     ]
    }
   ],
   "source": [
    "time_steps = range(1,12)\n",
    "spatial = 1\n",
    "results_df_single = pd.DataFrame()\n",
    "\n",
    "\n",
    "with tqdm(drought_cube.groupby('time.year')) as years_bar:\n",
    "    # group datacube by years\n",
    "    for iyear, icube in years_bar:\n",
    "\n",
    "        # Loop through time steps\n",
    "        for itime_step in time_steps:\n",
    "\n",
    "            # extract density cubes\n",
    "            vod_df, lst_df, ndvi_df, sm_df = get_density_cubes(icube, spatial, itime_step)\n",
    "\n",
    "\n",
    "            # get common elements\n",
    "            dfs = get_common_elements_many([vod_df, lst_df, ndvi_df, sm_df])\n",
    "            vod_df, lst_df, ndvi_df, sm_df = dfs[0], dfs[1], dfs[2], dfs[3]\n",
    "\n",
    "\n",
    "            variables = {\n",
    "                'VOD': vod_df,\n",
    "                'NDVI': ndvi_df,\n",
    "                'SM': sm_df,\n",
    "                'LST': lst_df\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "            # do calculations for H, TC\n",
    "            for (ivar1, ivar2) in common_vars:\n",
    "#             for iname, idata in variables.items():\n",
    "\n",
    "                # Pearson coeffcient\n",
    "                pears = stats.pearsonr(\n",
    "                    variables[ivar1].values.ravel(), \n",
    "                    variables[ivar2].values.ravel()\n",
    "                )[0]\n",
    "                \n",
    "                # Spearman Coefficient\n",
    "                spears = stats.spearmanr(\n",
    "                    variables[ivar1].values.ravel(), \n",
    "                    variables[ivar2].values.ravel()\n",
    "                )[0]\n",
    "\n",
    "                # normalize data\n",
    "                X_norm = StandardScaler().fit_transform(variables[ivar1])\n",
    "                Y_norm = StandardScaler().fit_transform(variables[ivar2])\n",
    "\n",
    "                # entropy, total correlation\n",
    "                mi, t_ = run_rbig_models(X_norm, Y_norm, measure=\"mi\", random_state=123)\n",
    "\n",
    "                # get H and TC\n",
    "                results_df_single = results_df_single.append({\n",
    "                    'year': iyear,\n",
    "                    'drought': drought_years[str(iyear)],\n",
    "                    'samples': X_norm.shape[0],\n",
    "                    'dimensions': X_norm.shape[1],\n",
    "                    'temporal': itime_step,\n",
    "                    'variable1': ivar1,\n",
    "                    'variable2': ivar2,\n",
    "                    'pearson': pears,\n",
    "                    'mi': mi,\n",
    "                    'time': t_,\n",
    "\n",
    "                }, ignore_index=True)\n",
    "            \n",
    "                postfix = dict(\n",
    "                    Year=f\"{iyear}\", \n",
    "                    Dims=f\"{itime_step}\",\n",
    "                    Variables=f\"{ivar1}-{ivar2}\",\n",
    "                    MI=f\"{mi:.3f}\",\n",
    "                    Pear=f\"{pears:.3f}\",\n",
    "                    Spear=f\"{spears:.3f}\",\n",
    "                )\n",
    "                years_bar.set_postfix(postfix)\n",
    "            # do calculations for \n",
    "            break\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimensions</th>\n",
       "      <th>mi</th>\n",
       "      <th>samples</th>\n",
       "      <th>temporal</th>\n",
       "      <th>time</th>\n",
       "      <th>variable1</th>\n",
       "      <th>variable2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>25779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.484674</td>\n",
       "      <td>VOD</td>\n",
       "      <td>NDVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>25779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.564911</td>\n",
       "      <td>VOD</td>\n",
       "      <td>LST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157174</td>\n",
       "      <td>25779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.743430</td>\n",
       "      <td>VOD</td>\n",
       "      <td>SM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>25779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.564871</td>\n",
       "      <td>NDVI</td>\n",
       "      <td>LST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.059311</td>\n",
       "      <td>25779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.583604</td>\n",
       "      <td>NDVI</td>\n",
       "      <td>SM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dimensions        mi  samples  temporal      time variable1 variable2\n",
       "0         1.0  0.014735  25779.0       1.0  2.484674       VOD      NDVI\n",
       "1         1.0  0.024350  25779.0       1.0  2.564911       VOD       LST\n",
       "2         1.0  0.157174  25779.0       1.0  2.743430       VOD        SM\n",
       "3         1.0  0.019120  25779.0       1.0  2.564871      NDVI       LST\n",
       "4         1.0  0.059311  25779.0       1.0  2.583604      NDVI        SM"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_single.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.08307110054436087, pvalue=1.0326962564352802e-40)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(variables[ivar1].values.ravel(), variables[ivar2].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-2019_rbig_ad]",
   "language": "python",
   "name": "conda-env-.conda-2019_rbig_ad-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
